{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from math import exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import copy\n",
    "import functools\n",
    "import itertools\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "from functools import partial\n",
    "from multiprocessing import Pool, cpu_count\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize\n",
    "from scipy.signal import fftconvolve\n",
    "from scipy.stats import norm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble._forest import BaseForest\n",
    "from sklearn.ensemble._bagging import BaseBagging\n",
    "from sklearn.ensemble._forest import _generate_sample_indices, _get_n_samples_bootstrap\n",
    "\n",
    "def gfit(X, sigma, p=5, nbin=200, unif_fraction=0.1):\n",
    "    \"\"\"\n",
    "    Fit empirical Bayes prior in the hierarchical model [Efron2014]_.\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        mu ~ G, X ~ N(mu, sigma^2)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: ndarray\n",
    "        A 1D array of observations.\n",
    "    sigma: float\n",
    "        Noise estimate on X.\n",
    "    p: int\n",
    "        Number of parameters used to fit G. Default: 5\n",
    "    nbin: int\n",
    "        Number of bins used for discrete approximation.\n",
    "        Default: 200\n",
    "    unif_fraction: float\n",
    "        Fraction of G modeled as \"slab\". Default: 0.1\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    An array of the posterior density estimate g.\n",
    "    \"\"\"\n",
    "    min_x = min(min(X) - 2 * np.std(X, ddof=1), 0)\n",
    "    max_x = max(max(X) + 2 * np.std(X, ddof=1),\n",
    "                np.std(X, ddof=1))\n",
    "    xvals = np.linspace(min_x, max_x, nbin)\n",
    "    binw = (max_x - min_x) / (nbin - 1)\n",
    "\n",
    "    zero_idx = max(np.where(xvals <= 0)[0])\n",
    "    noise_kernel = norm().pdf(xvals / sigma) * binw / sigma\n",
    "\n",
    "    if zero_idx > 0:\n",
    "        noise_rotate = noise_kernel[list(np.arange(zero_idx, len(xvals))) +\n",
    "                                    list(np.arange(0, zero_idx))]\n",
    "    else:\n",
    "        noise_rotate = noise_kernel\n",
    "\n",
    "    XX = np.zeros((p, len(xvals)), dtype=np.float)\n",
    "    for ind, exp in enumerate(range(1, p+1)):\n",
    "        mask = np.ones_like(xvals)\n",
    "        mask[np.where(xvals <= 0)[0]] = 0\n",
    "        XX[ind, :] = pow(xvals, exp) * mask\n",
    "    XX = XX.T\n",
    "\n",
    "    def neg_loglik(eta):\n",
    "        mask = np.ones_like(xvals)\n",
    "        mask[np.where(xvals <= 0)[0]] = 0\n",
    "        g_eta_raw = np.exp(np.dot(XX, eta)) * mask\n",
    "        if ((np.sum(g_eta_raw) == np.inf) |\n",
    "            (np.sum(g_eta_raw) <=\n",
    "                100 * np.finfo(np.double).tiny)):\n",
    "                return (1000 * (len(X) + sum(eta ** 2)))\n",
    "\n",
    "        g_eta_main = g_eta_raw / sum(g_eta_raw)\n",
    "        g_eta = ((1 - unif_fraction) * g_eta_main +\n",
    "                 unif_fraction * mask / sum(mask))\n",
    "        f_eta = fftconvolve(g_eta, noise_rotate, mode='same')\n",
    "        return np.sum(np.interp(X, xvals,\n",
    "                      -np.log(np.maximum(f_eta, 0.0000001))))\n",
    "\n",
    "    eta_hat = minimize(neg_loglik,\n",
    "                       list(itertools.repeat(-1, p))).x\n",
    "    g_eta_raw = np.exp(np.dot(XX, eta_hat)) * mask\n",
    "    g_eta_main = g_eta_raw / sum(g_eta_raw)\n",
    "    g_eta = ((1 - unif_fraction) * g_eta_main +\n",
    "             unif_fraction * mask) / sum(mask)\n",
    "\n",
    "    return xvals, g_eta\n",
    "\n",
    "\n",
    "def gbayes(x0, g_est, sigma):\n",
    "    \"\"\"\n",
    "    Estimate Bayes posterior with Gaussian noise [Efron2014]_.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x0: ndarray\n",
    "        an observation\n",
    "    g_est: float\n",
    "        a prior density, as returned by gfit\n",
    "    sigma: int\n",
    "        noise estimate\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    An array of the posterior estimate E[mu | x0]\n",
    "    \"\"\"\n",
    "\n",
    "    Kx = norm().pdf((g_est[0] - x0) / sigma)\n",
    "    post = Kx * g_est[1]\n",
    "    post /= sum(post)\n",
    "    return sum(post * g_est[0])\n",
    "\n",
    "\n",
    "def calibrateEB(variances, sigma2):\n",
    "    \"\"\"\n",
    "    Calibrate noisy variance estimates with empirical Bayes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    vars: ndarray\n",
    "        List of variance estimates.\n",
    "    sigma2: int\n",
    "        Estimate of the Monte Carlo noise in vars.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    An array of the calibrated variance estimates\n",
    "    \"\"\"\n",
    "    if (sigma2 <= 0 or min(variances) == max(variances)):\n",
    "        return(np.maximum(variances, 0))\n",
    "    sigma = np.sqrt(sigma2)\n",
    "    eb_prior = gfit(variances, sigma)\n",
    "    # Set up a partial execution of the function\n",
    "    part = functools.partial(gbayes, g_est=eb_prior,\n",
    "                             sigma=sigma)\n",
    "    if len(variances) >= 200:\n",
    "        # Interpolate to speed up computations:\n",
    "        calib_x = np.percentile(variances,\n",
    "                                np.arange(0, 102, 2))\n",
    "        calib_y = list(map(part, calib_x))\n",
    "        calib_all = np.interp(variances, calib_x, calib_y)\n",
    "    else:\n",
    "        calib_all = list(map(part, variances))\n",
    "\n",
    "    return np.asarray(calib_all)\n",
    "\n",
    "def compute_V(forest, X_train, X_test, calibrate=True):\n",
    "    def _infer_inbag(n_samples, forest):\n",
    "        n_trees = forest.n_estimators\n",
    "        inbag = np.zeros((n_samples, n_trees))\n",
    "        sample_idx = []\n",
    "        if isinstance(forest, BaseForest):\n",
    "            n_samples_bootstrap = _get_n_samples_bootstrap(n_samples, forest.max_samples)\n",
    "\n",
    "            for t_idx in range(n_trees):\n",
    "                sample_idx.append(\n",
    "                    _generate_sample_indices(\n",
    "                        forest.estimators_[t_idx].random_state,\n",
    "                        n_samples,\n",
    "                        n_samples_bootstrap,\n",
    "                    )\n",
    "                )\n",
    "                inbag[:, t_idx] = np.bincount(sample_idx[-1], minlength=n_samples)\n",
    "        elif isinstance(forest, BaseBagging):\n",
    "            for t_idx, estimator_sample in enumerate(forest.estimators_samples_):\n",
    "                sample_idx.append(estimator_sample)\n",
    "                inbag[:, t_idx] = np.bincount(sample_idx[-1], minlength=n_samples)\n",
    "\n",
    "        return inbag \n",
    "\n",
    "    def _core_computation_IJ(inbag, pred_centered, n_trees):\n",
    "        return np.sum((np.dot(inbag - 1, pred_centered.T) / n_trees) ** 2, 0) \n",
    "    \n",
    "    def _core_computation_J(inbag, pred, bagging_mean, n_samples):\n",
    "        noinbag = np.where(inbag>0, 0, 1)\n",
    "        delta_sum = np.dot(noinbag, pred.T)\n",
    "        theta_ = delta_sum/np.sum(noinbag, 1)\n",
    "        return (n_samples - 1)* np.mean((theta_ - bagging_mean.T)**2, 0)\n",
    "\n",
    "    def _bias_correction_IJ(V_IJ, inbag, pred_centered, n_trees):\n",
    "        n_train_samples = inbag.shape[0]\n",
    "        n_var = np.mean(\n",
    "            np.square(inbag[0:n_trees]).mean(axis=1).T.view()\n",
    "            - np.square(inbag[0:n_trees].mean(axis=1)).T.view()\n",
    "        )\n",
    "        boot_var = np.square(pred_centered).sum(axis=1) / n_trees\n",
    "        bias_correction = n_train_samples * n_var * boot_var / n_trees\n",
    "        V_IJ_unbiased = V_IJ - bias_correction\n",
    "        return V_IJ_unbiased \n",
    "    \n",
    "    def _bias_correction_J(V_J, inbag, pred_centered, n_trees):\n",
    "        n_train_samples = inbag.shape[0]\n",
    "        n_var = np.mean(\n",
    "            np.square(inbag[0:n_trees]).mean(axis=1).T.view()\n",
    "            - np.square(inbag[0:n_trees].mean(axis=1)).T.view()\n",
    "        )\n",
    "        boot_var = np.square(pred_centered).sum(axis=1) / n_trees\n",
    "        bias_correction = (exp(1) - 1) * n_train_samples * n_var * boot_var / n_trees\n",
    "        V_J_unbiased = V_J - bias_correction\n",
    "        return V_J_unbiased \n",
    "\n",
    "    inbag = _infer_inbag(X_train.shape[0], forest) \n",
    "    pred = np.array([tree.predict(X_test) for tree in forest]).T\n",
    "    pred_mean = np.mean(pred, 0)\n",
    "    bagging_mean = np.mean(pred, 1)\n",
    "    pred_centered = pred - pred_mean\n",
    "    n_trees = forest.n_estimators\n",
    "    V_J = _core_computation_J(inbag, pred, bagging_mean, X_train.shape[0])\n",
    "    V_J_unbiased = _bias_correction_J(V_J, inbag, pred_centered, n_trees)\n",
    "    V_IJ = _core_computation_IJ(inbag, pred_centered, n_trees)\n",
    "    V_IJ_unbiased = _bias_correction_IJ(V_IJ, inbag, pred_centered, n_trees)\n",
    "    print(V_J[:10], V_J_unbiased[:10], V_IJ[:10], V_IJ_unbiased[:10])\n",
    "    # calibration\n",
    "    if calibrate:\n",
    "        calibration_ratio = 2\n",
    "        n_sample = np.ceil(n_trees / calibration_ratio)\n",
    "        new_forest = copy.deepcopy(forest)\n",
    "        random_idx = np.random.permutation(len(new_forest.estimators_))[: int(n_sample)]\n",
    "        new_forest.estimators_ = list(np.array(new_forest.estimators_)[random_idx])\n",
    "        if hasattr(new_forest, \"_seeds\"):\n",
    "            new_forest._seeds = new_forest._seeds[random_idx]\n",
    "\n",
    "        new_forest.n_estimators = int(n_sample)\n",
    "        _, results_ss_J_, _,results_ss_IJ = compute_V(\n",
    "            new_forest,\n",
    "            X_train,\n",
    "            X_test,\n",
    "            calibrate=False\n",
    "        )\n",
    "        # Use this second set of variance estimates\n",
    "        # to estimate scale of Monte Carlo noise\n",
    "        sigma2_ss_J = np.mean((results_ss_J_ - V_J_unbiased) ** 2)\n",
    "        sigma2_ss_IJ = np.mean((results_ss_IJ - V_IJ_unbiased) ** 2)\n",
    "        delta = n_sample / n_trees\n",
    "        sigma2_J = (delta ** 2 + (1 - delta) ** 2) / (2 * (1 - delta) ** 2) * sigma2_ss_J\n",
    "        sigma2_IJ = (delta ** 2 + (1 - delta) ** 2) / (2 * (1 - delta) ** 2) * sigma2_ss_IJ\n",
    "\n",
    "        # Use Monte Carlo noise scale estimate for empirical Bayes calibration\n",
    "        V_J_calibrated = calibrateEB(V_J, sigma2_J)\n",
    "        V_J_U_calibrated = calibrateEB(V_J_unbiased, sigma2_J)\n",
    "        V_IJ_calibrated = calibrateEB(V_IJ, sigma2_IJ)\n",
    "        V_IJ_U_calibrated = calibrateEB(V_IJ_unbiased, sigma2_IJ)\n",
    "        return V_J_calibrated, V_J_U_calibrated, V_IJ_calibrated, V_IJ_U_calibrated\n",
    "    return V_J, V_J_unbiased, V_IJ, V_IJ_unbiased"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compliance</th>\n",
       "      <th>cholesterol.decrease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.2510</td>\n",
       "      <td>11.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.2510</td>\n",
       "      <td>-6.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.2510</td>\n",
       "      <td>-7.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-2.2510</td>\n",
       "      <td>-5.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.8312</td>\n",
       "      <td>-23.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   compliance  cholesterol.decrease\n",
       "0     -2.2510                 11.50\n",
       "1     -2.2510                 -6.25\n",
       "2     -2.2510                 -7.25\n",
       "3     -2.2510                 -5.25\n",
       "4     -1.8312                -23.00"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table('cholesterol.txt', sep = ' ')\n",
    "X0 = df['compliance'].values.reshape((-1,1))\n",
    "y0 = df['cholesterol.decrease'].values\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_3(n_estimators, random_seed):\n",
    "    np.random.seed(random_seed)\n",
    "    sigma = 22.0\n",
    "    B = n_estimators\n",
    "    random_seed = 0\n",
    "    degrees = range(1, 7)\n",
    "    Cp = list()\n",
    "    for degree in degrees:\n",
    "        X = PolynomialFeatures(degree).fit_transform(X0)  \n",
    "        bagging = BaggingRegressor(base_estimator=LinearRegression(), n_estimators=B, random_state=random_seed)\n",
    "        bagging.fit(X, y0)\n",
    "        Cp.append(np.linalg.norm(bagging.predict(X) - y0)**2 + 2*sigma**2*degree)\n",
    "        \n",
    "    degree = degrees[np.argmin(Cp)]\n",
    "    X = PolynomialFeatures(degree).fit_transform(X0)\n",
    "    bagging = BaggingRegressor(base_estimator=LinearRegression(), n_estimators=B, random_state=random_seed)\n",
    "    bagging.fit(X, y0)\n",
    "    V_J, V_J_U, V_IJ, V_IJ_U = compute_VIJ(bagging, X, X)\n",
    "    return V_J[0], V_J_U[0], V_IJ[0], V_IJ_U[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'degrees' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-b261c955c004>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# from CI import compute_VIJ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdegree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdegrees\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPolynomialFeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2.25\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'start to compute'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'degrees' is not defined"
     ]
    }
   ],
   "source": [
    "# from CI import compute_VIJ\n",
    "degree = degrees[np.argmin(Cp)]\n",
    "X = PolynomialFeatures(degree).fit_transform(X0)\n",
    "X_test = PolynomialFeatures(degree).fit_transform(np.array([[-2.25]]))\n",
    "print('start to compute')\n",
    "bagging = BaggingRegressor(base_estimator = LinearRegression(), n_estimators = B, random_state = random_seed)\n",
    "bagging.fit(X, y)\n",
    "V_J, V_J_U, V_IJ, V_IJ_U = compute_VIJ(bagging, X, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[136.74632856  87.19631972 117.70915531  83.18696066  18.64005364\n",
      "  22.88697349  22.19320423  27.78778612  21.59194873  25.66203465] [-1169.64428391 -1219.19429275 -1188.68145716 -1223.20365181\n",
      " -1482.87094617 -1478.62402632 -1479.31779558 -1436.8228398\n",
      " -1443.01867719 -1382.26082708] [806.51303157 806.51303157 806.51303157 806.51303157 856.16801564\n",
      " 856.16801564 856.16801564 823.31372655 823.31372655 786.46449238] [ 46.22412504  46.22412504  46.22412504  46.22412504 -17.67641135\n",
      " -17.67641135 -17.67641135 -29.05554237 -29.05554237 -32.91381822]\n",
      "[166.53530085 151.01391574 249.642012   137.64970158  25.77294336\n",
      "  41.31590655  27.65367593  34.2247145   23.76998225  26.32046362] [-2376.58339478 -2392.10477989 -2293.47668363 -2405.46899405\n",
      " -2963.52560577 -2947.98264258 -2961.64487321 -2897.5478538\n",
      " -2908.00258604 -2800.01798572] [1427.51076342 1427.51076342 1427.51076342 1427.51076342 1609.21181775\n",
      " 1609.21181775 1609.21181775 1565.28877202 1565.28877202 1503.2016915 ] [ -52.52508025  -52.52508025  -52.52508025  -52.52508025 -130.49030772\n",
      " -130.49030772 -130.49030772 -140.93457257 -140.93457257 -141.66145174]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: RuntimeWarning: overflow encountered in exp\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:86: RuntimeWarning: invalid value encountered in true_divide\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(nan, nan, 806.5130315705017, 37.40910393061422)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figure_3(200, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(164, 200)(164, 200)  (164, 200)(164, 200)\n",
      "\n",
      "(164, 200) (164, 200)(164, 200)\n",
      " (164, 200)(164, 200) \n",
      "(164, 200)(164, 200)\n",
      " (164, 200)(164, 200)(164, 200)\n",
      " (164, 200) (164, 200)(164, 200) (164, 200)\n",
      "(164, 200)\n",
      " \n",
      "(164, 200)\n",
      "(164, 500) (164, 500)\n",
      "(164, 500) (164, 500)(164, 500) (164, 500)\n",
      "\n",
      "(164, 500) (164, 500)\n",
      "(164, 500) (164, 500)\n",
      "(164, 500)(164, 500)  (164, 500)(164, 500)\n",
      "\n",
      "(164, 500) (164, 500)\n",
      "(164, 500) (164, 500)\n",
      "(164, 500) (164, 500)\n",
      "(164, 1000) (164, 1000)\n",
      "(164, 1000) (164, 1000)\n",
      "(164, 1000) (164, 1000)\n",
      "(164, 1000) (164, 1000)\n",
      "(164, 1000) (164, 1000)\n",
      "(164, 1000) (164, 1000)\n",
      "(164, 1000) (164, 1000)\n",
      "(164, 1000) (164, 1000)\n",
      "(164, 1000) (164, 1000)\n",
      "(164, 1000) (164, 1000)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-109:\n",
      "Process ForkPoolWorker-107:\n",
      "Process ForkPoolWorker-101:\n",
      "Process ForkPoolWorker-108:\n",
      "Process ForkPoolWorker-105:\n",
      "Process ForkPoolWorker-103:\n",
      "Process ForkPoolWorker-110:\n",
      "Process ForkPoolWorker-102:\n",
      "Process ForkPoolWorker-104:\n",
      "Process ForkPoolWorker-106:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"<ipython-input-60-f771f3d1461f>\", line 11, in figure_3\n",
      "    bagging.fit(X, y0)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n",
      "    result = (True, func(*args, **kwds))\n",
      "  File \"<ipython-input-60-f771f3d1461f>\", line 11, in figure_3\n",
      "    bagging.fit(X, y0)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"<ipython-input-60-f771f3d1461f>\", line 11, in figure_3\n",
      "    bagging.fit(X, y0)\n",
      "  File \"<ipython-input-60-f771f3d1461f>\", line 11, in figure_3\n",
      "    bagging.fit(X, y0)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"<ipython-input-60-f771f3d1461f>\", line 11, in figure_3\n",
      "    bagging.fit(X, y0)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"<ipython-input-60-f771f3d1461f>\", line 11, in figure_3\n",
      "    bagging.fit(X, y0)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 243, in fit\n",
      "    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 243, in fit\n",
      "    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 47, in starmapstar\n",
      "    return list(itertools.starmap(args[0], args[1]))\n",
      "  File \"<ipython-input-60-f771f3d1461f>\", line 11, in figure_3\n",
      "    bagging.fit(X, y0)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 243, in fit\n",
      "    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 243, in fit\n",
      "    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n",
      "  File \"<ipython-input-60-f771f3d1461f>\", line 11, in figure_3\n",
      "    bagging.fit(X, y0)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 243, in fit\n",
      "    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n",
      "  File \"<ipython-input-60-f771f3d1461f>\", line 11, in figure_3\n",
      "    bagging.fit(X, y0)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 243, in fit\n",
      "    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 380, in _fit\n",
      "    for i in range(n_jobs))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 380, in _fit\n",
      "    for i in range(n_jobs))\n",
      "  File \"<ipython-input-60-f771f3d1461f>\", line 11, in figure_3\n",
      "    bagging.fit(X, y0)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 243, in fit\n",
      "    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 380, in _fit\n",
      "    for i in range(n_jobs))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 243, in fit\n",
      "    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 380, in _fit\n",
      "    for i in range(n_jobs))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 243, in fit\n",
      "    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 380, in _fit\n",
      "    for i in range(n_jobs))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 380, in _fit\n",
      "    for i in range(n_jobs))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 243, in fit\n",
      "    return self._fit(X, y, self.max_samples, sample_weight=sample_weight)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 380, in _fit\n",
      "    for i in range(n_jobs))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 380, in _fit\n",
      "    for i in range(n_jobs))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 380, in _fit\n",
      "    for i in range(n_jobs))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 380, in _fit\n",
      "    for i in range(n_jobs))\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 1029, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 847, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 765, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 206, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/_parallel_backends.py\", line 570, in __init__\n",
      "    self.results = batch()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 110, in _parallel_build_estimators\n",
      "    estimator.fit(X[:, features], y, sample_weight=curr_sample_weight)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 87, in _parallel_build_estimators\n",
      "    random_state=random_state)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 87, in _parallel_build_estimators\n",
      "    random_state=random_state)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 87, in _parallel_build_estimators\n",
      "    random_state=random_state)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 87, in _parallel_build_estimators\n",
      "    random_state=random_state)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 110, in _parallel_build_estimators\n",
      "    estimator.fit(X[:, features], y, sample_weight=curr_sample_weight)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_base.py\", line 515, in fit\n",
      "    return_mean=True)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 253, in __call__\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 110, in _parallel_build_estimators\n",
      "    estimator.fit(X[:, features], y, sample_weight=curr_sample_weight)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_base.py\", line 151, in _make_estimator\n",
      "    estimator = clone(self.base_estimator_)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 87, in _parallel_build_estimators\n",
      "    random_state=random_state)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_base.py\", line 156, in _make_estimator\n",
      "    _set_random_states(estimator, random_state)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_base.py\", line 151, in _make_estimator\n",
      "    estimator = clone(self.base_estimator_)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_base.py\", line 156, in _make_estimator\n",
      "    _set_random_states(estimator, random_state)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_base.py\", line 161, in _preprocess_data\n",
      "    X -= X_offset\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/joblib/parallel.py\", line 253, in <listcomp>\n",
      "    for func, args, kwargs in self.items]\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_base.py\", line 519, in fit\n",
      "    X, y = _rescale_data(X, y, sample_weight)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_base.py\", line 519, in fit\n",
      "    X, y = _rescale_data(X, y, sample_weight)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_base.py\", line 156, in _make_estimator\n",
      "    _set_random_states(estimator, random_state)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 110, in _parallel_build_estimators\n",
      "    estimator.fit(X[:, features], y, sample_weight=curr_sample_weight)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_base.py\", line 72, in _set_random_states\n",
      "    random_state = check_random_state(random_state)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_base.py\", line 72, in _set_random_states\n",
      "    random_state = check_random_state(random_state)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_bagging.py\", line 110, in _parallel_build_estimators\n",
      "    estimator.fit(X[:, features], y, sample_weight=curr_sample_weight)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_base.py\", line 203, in _rescale_data\n",
      "    X = safe_sparse_dot(sw_matrix, X)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_base.py\", line 203, in _rescale_data\n",
      "    X = safe_sparse_dot(sw_matrix, X)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/base.py\", line 87, in clone\n",
      "    new_object_params[name] = clone(param, safe=False)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/_base.py\", line 72, in _set_random_states\n",
      "    random_state = check_random_state(random_state)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_base.py\", line 515, in fit\n",
      "    return_mean=True)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\", line 865, in check_random_state\n",
      "    return np.random.RandomState(seed)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/base.py\", line 89, in clone\n",
      "    params_set = new_object.get_params(deep=False)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\", line 865, in check_random_state\n",
      "    return np.random.RandomState(seed)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_base.py\", line 515, in fit\n",
      "    return_mean=True)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\", line 865, in check_random_state\n",
      "    return np.random.RandomState(seed)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_base.py\", line 160, in _preprocess_data\n",
      "    X_offset = np.average(X, axis=0, weights=sample_weight)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/base.py\", line 207, in get_params\n",
      "    value = getattr(self, key)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py\", line 153, in safe_sparse_dot\n",
      "    ret = a @ b\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_base.py\", line 129, in _preprocess_data\n",
      "    dtype=FLOAT_DTYPES)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/base.py\", line 71, in clone\n",
      "    return copy.deepcopy(estimator)\n",
      "  File \"<__array_function__ internals>\", line 6, in average\n",
      "  File \"mtrand.pyx\", line 182, in numpy.random.mtrand.RandomState.__init__\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/utils/extmath.py\", line 153, in safe_sparse_dot\n",
      "    ret = a @ b\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/scipy/sparse/base.py\", line 564, in __matmul__\n",
      "    return self.__mul__(other)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\", line 73, in inner_f\n",
      "    return f(**kwargs)\n",
      "  File \"/usr/lib/python3.6/copy.py\", line 132, in deepcopy\n",
      "    def deepcopy(x, memo=None, _nil=[]):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/scipy/sparse/base.py\", line 564, in __matmul__\n",
      "    return self.__mul__(other)\n",
      "  File \"_mt19937.pyx\", line 129, in numpy.random._mt19937.MT19937.__init__\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/numpy/lib/function_base.py\", line 407, in average\n",
      "    scl = wgt.sum(axis=axis, dtype=result_dtype)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/scipy/sparse/base.py\", line 475, in __mul__\n",
      "    return self._mul_multivector(other)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\", line 560, in check_array\n",
      "    if estimator is not None:\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py\", line 47, in _sum\n",
      "    return umr_sum(a, axis, dtype, out, keepdims, initial, where)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/scipy/sparse/base.py\", line 475, in __mul__\n",
      "    return self._mul_multivector(other)\n",
      "  File \"bit_generator.pyx\", line 526, in numpy.random.bit_generator.BitGenerator.__init__\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/scipy/sparse/base.py\", line 540, in _mul_multivector\n",
      "    return self.tocsr()._mul_multivector(other)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/scipy/sparse/base.py\", line 540, in _mul_multivector\n",
      "    return self.tocsr()._mul_multivector(other)\n",
      "  File \"bit_generator.pyx\", line 305, in numpy.random.bit_generator.SeedSequence.__init__\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/scipy/sparse/base.py\", line 894, in tocsr\n",
      "    return self.tocoo(copy=copy).tocsr(copy=False)\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/lib/python3.6/random.py\", line 680, in getrandbits\n",
      "    def getrandbits(self, k):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/scipy/sparse/coo.py\", line 400, in tocsr\n",
      "    maxval=max(self.nnz, N))\n",
      "KeyboardInterrupt\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/scipy/sparse/sputils.py\", line 148, in get_index_dtype\n",
      "    if maxval > int32max:\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mstarmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0;31m`\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mbecomes\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         '''\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m     def starmap_async(self, func, iterable, chunksize=None, callback=None,\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_process = 10\n",
    "n_parallel = 10\n",
    "random_seeds = list(range(n_parallel))\n",
    "baggings = [200, 500, 1000, 2000]\n",
    "with Pool(processes = n_process) as pool:\n",
    "    collection_source = pool.starmap(figure_3, product(baggings, random_seeds))\n",
    "\n",
    "collection_source = np.array(collection_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "xoffset = 5\n",
    "inoffset = 1\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.set_title('Figure 3')\n",
    "boxs = list()\n",
    "boxs.append(ax1.boxplot([collection_source[i*n_parallel:(i+1)*n_parallel, 0] for i in range(len(baggings))],\n",
    "                                                    positions = [xoffset*i for i in range(len(baggings))], patch_artist=True))\n",
    "boxs.append(ax1.boxplot([collection_source[i*n_parallel:(i+1)*n_parallel, 1] for i in range(len(baggings))],\n",
    "                                                    positions = [xoffset*i+inoffset for i in range(len(baggings))], patch_artist=True))\n",
    "colors = ['pink', 'lightblue', 'lightgreen']\n",
    "for i in range(2):\n",
    "    for j in range(len(baggings)):\n",
    "        boxs[i]['boxes'][j].set_facecolor(colors[i])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 0, 0]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([[1,2,0], [4,5,6]])\n",
    "np.where(a>0, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(a).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
